{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/MUDSS/lectures/raw/main/semester-2-2021-2022/week-5-bootcamp-tensorflow-keras/assets/cover.png\" alt=\"Week 5: TensorFlow & Keras\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "\n",
    "<img src=\"https://www.gstatic.com/devrel-devsite/prod/v2484c9574f819dcf3d7ffae39fb3001f4498b2ece38cec22517931d550e19e7d/tensorflow/images/lockup.svg\" alt=\"TensorFlow\" width='200' align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrXv0rU9sIma"
   },
   "source": [
    "# TensorFlow Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJyZUDbzBTIG"
   },
   "source": [
    "TensorFlow is a free and open-source end-to-end platform for machine learning and artificial intelligence which gives developers the ability to easily build and deploy ML-powered applications. It was developed by the Google Brain team for internal Google use in research and production, then brought to public in 2015 and updated to TensorFlow 2.0 in 2019.\n",
    "\n",
    "TensorFlow can be used in a wide variety of programming languages, including Python, C++, Javascript, Java, and could run on various platforms like desktop, server, web front-end, and embedded systems, etc.\n",
    "\n",
    "It supports the following:\n",
    "\n",
    "* Multidimensional-array based numeric computation (similar to <a href=\"https://numpy.org/\" class=\"external\">NumPy</a>.)\n",
    "* GPU and distributed processing\n",
    "* Automatic differentiation\n",
    "* Model construction, training, and export\n",
    "* And more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-mi5031DVxz"
   },
   "source": [
    "When [properly configured](https://www.tensorflow.org/install/gpu), TensorFlow can use accelerator hardware like GPUs to execute operations very quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m97Gv5H6Dz0G"
   },
   "outputs": [],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"TensorFlow **IS** using the GPU\")\n",
    "else:\n",
    "    print(\"TensorFlow **IS NOT** using the GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvLegMMvBZYg"
   },
   "source": [
    "## Tensors\n",
    "\n",
    "TensorFlow operates on multidimensional arrays or _tensors_ represented as [`tf.Tensor`](https://www.tensorflow.org/api_docs/python/tf/Tensor) objects. Here is a two-dimensional tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ZqX5RnbBS1f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-AOMqevQGN4"
   },
   "source": [
    "The most important attributes of a `tf.Tensor` are its `shape` and `dtype`:\n",
    "\n",
    "* `Tensor.shape`: tells you the size of the tensor along each of its axes.\n",
    "* `Tensor.dtype`: tells you the type of all the elements in the tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUkKeNWZCIJO"
   },
   "source": [
    "TensorFlow implements standard mathematical operations on tensors, as well as many operations specialized for machine learning.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BM7xXNDsBfN5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLGqscTxB61v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ImJHd8VfnWq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9JZD6TYCZWu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZNZRv1ECjf8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "seGBLeD9P_PI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVbomvMyEIVF"
   },
   "source": [
    "## Variables\n",
    "\n",
    "Normal `tf.Tensor` objects are immutable. To store model weights (or other mutable state) in TensorFlow use a [`tf.Variable`](https://www.tensorflow.org/api_docs/python/tf/Variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SO8_bP4UEzxS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aDLYFvu5FAFa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EpiOmxXFDSS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rG1Dhv2QFkV3"
   },
   "source": [
    "## Automatic differentiation\n",
    "\n",
    "<a href=\"https://en.wikipedia.org/wiki/Gradient_descent\" class=\"external\">_Gradient descent_</a> and related algorithms are a cornerstone of modern machine learning.\n",
    "\n",
    "To enable this, TensorFlow implements automatic differentiation (autodiff), which uses calculus to compute gradients. Typically you'll use this to calculate the gradient of a model's _error_ or _loss_ with respect to its weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing gradients\n",
    "\n",
    "To differentiate automatically, TensorFlow needs to remember what operations happen in what order during the *forward* pass.  Then, during the *backward pass*, TensorFlow traverses this list of operations in reverse order to compute gradients.\n",
    "\n",
    "Here is a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cYKOi-z4GY9Y"
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(1.0)\n",
    "\n",
    "def f(x):\n",
    "    return x**2 + 2*x - 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozLLop0cHeYl"
   },
   "source": [
    "At `x = 1.0`, `y = f(x) = (1**2 + 2*1 - 5) = -2`.\n",
    "\n",
    "The derivative of `y` is `y' = f'(x) = (2*x + 2) = 4`. TensorFlow can calculate this automatically:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient tapes\n",
    "\n",
    "TensorFlow provides the `tf.GradientTape` API for automatic differentiation; that is, computing the gradient of a computation with respect to some inputs, usually `tf.Variable`s.\n",
    "TensorFlow \"records\" relevant operations executed inside the context of a `tf.GradientTape` onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using [reverse mode differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N02NfWpHGvw8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-DVYJfcIRPd"
   },
   "source": [
    "This simplified example only takes the derivative with respect to a single scalar (`x`), but TensorFlow can compute the gradient with respect to any number of non-scalar tensors simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VglUM4M3KhNz"
   },
   "source": [
    "## Eager Execution and Graphs\n",
    "\n",
    "For all codes we executed above are under a running mode of TensorFlow called *Eager Execution*. It evaluates values instantly rather than building a computation graph for later use which is compulsory in TensorFlow 1.0. Eager Execution is exactly like how Python scripts does.\n",
    "\n",
    "While we can use TensorFlow interactively like any Python library, TensorFlow also provides tools for:\n",
    "\n",
    "* **Performance optimization**: to speed up training and inference.\n",
    "* **Export**: so you can save your model when it's done training.\n",
    "\n",
    "These require that you use `tf.function` to separate your pure-TensorFlow code from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VitACyZWKJD_"
   },
   "outputs": [],
   "source": [
    "\n",
    "def my_func(x):\n",
    "    print('Tracing...')\n",
    "    y = x + 5\n",
    "    return tf.reduce_sum(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBYDh-huNUBZ"
   },
   "source": [
    "The first time you run the `tf.function`, although it executes in Python, it captures a complete, optimized graph representing the TensorFlow computations done within the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkOFSEkoM1bd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3aWzt-rNsBa"
   },
   "source": [
    "On subsequent calls TensorFlow only executes the optimized graph, skipping any non-TensorFlow steps. Below, note that `my_func` doesn't print _tracing_ since `print` is a Python function, not a TensorFlow function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23dMHWwwNIoa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSeTti6zki0n"
   },
   "source": [
    "A graph may not be reusable for inputs with a different _signature_ (`shape` and `dtype`), so a new graph is generated instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OWffqyhqlVPf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWknAA_zNTOa"
   },
   "source": [
    "These captured graphs provide two benefits:\n",
    "\n",
    "* In many cases they provide a significant speedup in execution.\n",
    "* You can export these graphs, using `tf.saved_model`, to run on other systems like a [server](https://www.tensorflow.org/tfx/serving/docker) or a [mobile device](https://www.tensorflow.org/lite/guide), no Python installation required.\n",
    "\n",
    "In short, graphs are extremely useful and let your TensorFlow run fast, run in parallel, and run efficiently on multiple devices.\n",
    "\n",
    "However, you still want to define your machine learning models (or other computations) in Python for convenience, and then automatically construct graphs when you need them. And note that the process of creating graphs has some overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_36xPDPPBqp"
   },
   "source": [
    "## Modules, layers, and models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDaT7kCpUgnJ"
   },
   "source": [
    "`tf.Module` is a class for managing your `tf.Variable` objects, and the `tf.function` objects that operate on them. One of significant features of Module is that we can save and load a Module anytime from or to multiple platforms. We will see this in Keras example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1MqEcZOqPBDV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "la2G82HfVfU0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxU6P1RGwHyC"
   },
   "source": [
    "The `tf.keras.layers.Layer` and `tf.keras.Model` classes build on `tf.Module` providing additional functionality and convenience methods for building, training, and saving models.\n",
    "\n",
    "A model is, abstractly:\n",
    "\n",
    "+ A function that computes something on tensors (a forward pass)\n",
    "+ Some variables that can be updated in response to training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next —— tf.keras\n",
    "\n",
    "You may have noticed that classes `Layer` and `Model` are both provided by package `tf.keras` which is the next important role for this session. In the past, Keras is an independent package based on TF, but now it has become an indispensable part of TensorFlow 2.0 ecosystem.\n",
    "\n",
    "Keras is built upon TensorFlow and provides us high-level encapsulation on data preprocessing, building model, training, and so on. It significantly simplifies workflow of modern data scientists and enables us quickly transform data science ideas into practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "\n",
    "<img src=\"https://www.gstatic.com/devrel-devsite/prod/v2484c9574f819dcf3d7ffae39fb3001f4498b2ece38cec22517931d550e19e7d/tensorflow/images/lockup.svg\" alt=\"TensorFlow\" width='200' align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYysdyb-CaWM"
   },
   "source": [
    "# Keras - Basic classification: Classify MNIST images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbVhjPpzn6BM"
   },
   "source": [
    "This notebook trains a neural network model to classify images of handwritten digits. This is a fast-paced overview of a complete TensorFlow program especially making use of Keras Sequential API.\n",
    "\n",
    "This guide uses [tf.keras](https://www.tensorflow.org/guide/keras), a user-friendly high-level API to build and train models in TensorFlow, whose Sequential API helps us build models by plugging together building blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dzLKpmZICaWN"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yR0EdgrLCaWR"
   },
   "source": [
    "## Import the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLdCchMdCaWQ"
   },
   "source": [
    "This guide uses the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset which contains 70,000 grayscale images in 10 categories. The images show individual handwritten digit at low resolution (28 by 28 pixels), as seen here:\n",
    "\n",
    "<img src=\"https://github.com/MUDSS/lectures/raw/main/semester-2-2021-2022/week-5-bootcamp-tensorflow-keras/assets/mnist_sprites.png\" alt=\"MNIST sprite\" width=\"600\">\n",
    "\n",
    "MNIST is often used as the **\"Hello, World\"** of machine learning programs for computer vision. It is a good starting point to test and debug code.\n",
    "\n",
    "Here, 60,000 images are used to train the network and 10,000 images to evaluate how accurately the network learned to classify images. We can access the MNIST directly from Keras datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7MqDQO0KCaWS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9FDsUlxCaWW"
   },
   "source": [
    "Loading the dataset returns four NumPy arrays:\n",
    "\n",
    "* The `train_images` and `train_labels` arrays are the *training set*—the data the model uses to learn.\n",
    "* The model is tested against the *test set*, the `test_images`, and `test_labels` arrays.\n",
    "\n",
    "The images are 28x28 NumPy arrays, with pixel values ranging from 0 to 255. The *labels* are an array of integers, ranging from 0 to 9. These correspond to the *class* of the real digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ES6uQoLKCaWr"
   },
   "source": [
    "## Preprocess the data\n",
    "\n",
    "The data must be preprocessed before training the network. If you inspect the first image in the training set, you will see that the pixel values fall in the range of 0 to 255:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4VEw8Ud9Quh"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0], cmap='Greys')\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wz7l27Lz9S1P"
   },
   "source": [
    "Scale these values to a range of 0 to 1 before feeding them to the neural network model. To do so, divide the values by 255. It's important that the *training set* and the *testing set* be preprocessed in the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bW5WzIPlCaWv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ee638AlnCaWz"
   },
   "source": [
    "To verify that the data is in the correct format and that you're ready to build and train the network, let's display the first 25 images from the *training set* and display the class name below each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZTImqg_CaW1"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(train_labels[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59veuiEZCaW4"
   },
   "source": [
    "## Build the model\n",
    "\n",
    "Building the neural network requires configuring the layers of the model, then compiling the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gxg1XGm0eOBy"
   },
   "source": [
    "## Set up the layers\n",
    "\n",
    "The basic building block of a neural network is the [*layer*](https://www.tensorflow.org/api_docs/python/tf/keras/layers). Layers extract representations from the data fed into them. Hopefully, these representations are meaningful for the problem at hand.\n",
    "\n",
    "Most of deep learning consists of chaining together simple layers. Most layers, such as `tf.keras.layers.Dense`, have parameters that are learned during training.\n",
    "\n",
    "A [Sequential](https://www.tensorflow.org/guide/keras/sequential_model) model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ODch-OFCaW4"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    \n",
    "], name='my_model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gut8A_7rCaW6"
   },
   "source": [
    "The first layer in this network, `tf.keras.layers.Flatten`, transforms the format of the images from a two-dimensional array (of 28 by 28 pixels) to a one-dimensional array (of 28 * 28 = 784 pixels). Think of this layer as unstacking rows of pixels in the image and lining them up. This layer has no parameters to learn; it only reformats the data.\n",
    "\n",
    "After the pixels are flattened, the network consists of a sequence of two `tf.keras.layers.Dense` layers. These are densely connected, or fully connected, neural layers. The first `Dense` layer has 128 nodes (or neurons). The second (and last) layer returns a logits array with length of 10. Each node contains a score that indicates the current image belongs to one of the 10 classes.\n",
    "\n",
    "### Compile the model\n",
    "\n",
    "Before the model is ready for training, it needs a few more settings. These are added during the model's [*compile*](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile) step:\n",
    "\n",
    "* [*Optimizer*](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers) —This is how the model is updated based on the data it sees and its loss function.\n",
    "* [*Loss function*](https://www.tensorflow.org/api_docs/python/tf/keras/losses) —This measures how accurate the model is during training. You want to minimize this function to \"steer\" the model in the right direction.\n",
    "* [*Metrics*](https://www.tensorflow.org/api_docs/python/tf/keras/metrics) —Used to monitor the training and testing steps. The following example uses *accuracy*, the fraction of the images that are correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lhan11blCaW7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKF6uW-BCaW-"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "Training the neural network model requires the following steps:\n",
    "\n",
    "1. Feed the training data to the model. In this example, the training data is in the `train_images` and `train_labels` arrays.\n",
    "2. The model learns to associate images and labels.\n",
    "3. You ask the model to make predictions about a test set—in this example, the `test_images` array.\n",
    "4. Verify that the predictions match the labels from the `test_labels` array.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4P4zIV7E28Z"
   },
   "source": [
    "### Feed the model\n",
    "\n",
    "To start training,  call the [`model.fit`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) method—so called because it \"fits\" the model to the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xvwvpA64CaW_"
   },
   "outputs": [],
   "source": [
    "# set up tensorboard callback\n",
    "logdir = \"logs/\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3ZVOhugCaXA"
   },
   "source": [
    "As the model trains, the loss and accuracy metrics are displayed. This model reaches an accuracy of about 0.91 (or 91%) on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCpr6DGyE28h"
   },
   "source": [
    "### Evaluate accuracy\n",
    "\n",
    "Next, compare how the model performs on the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VflXLEeECaXC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWfgsmVXCaXG"
   },
   "source": [
    "It turns out that the accuracy on the test dataset is a little better than the accuracy on the training dataset. This gap between training accuracy and test accuracy represents *underfitting*. Or we could say it generalises well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-PyD1SYE28q"
   },
   "source": [
    "### Make predictions\n",
    "\n",
    "With the model trained, you can use it to make predictions about some images.\n",
    "Attach a softmax layer to convert the model's linear outputs—[logits](https://developers.google.com/machine-learning/glossary#logits)—to probabilities, which should be easier to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DnfNA0CrQLSD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gl91RPhdCaXI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9Kk1voUCaXJ"
   },
   "source": [
    "Here, the model has predicted the label for each image in the testing set. Let's take a look at the first prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3DmJEUinCaXK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hw1hgeSCaXN"
   },
   "source": [
    "A prediction is an array of 10 numbers. They represent the model's \"confidence\" that the image corresponds to each of the 10 different digits. You can see which label has the highest confidence value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qsqenuPnCaXO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E51yS7iCCaXO"
   },
   "source": [
    "So, the model is most confident that this image is number $7$. Examining the test label shows that this classification is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sd7Pgsu6CaXP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygh2yYC972ne"
   },
   "source": [
    "Graph this to look at the full set of 10 class predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DvYmmrpIy6Y1"
   },
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    true_label, img = true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(predicted_label,\n",
    "                                  100*np.max(predictions_array),\n",
    "                                  true_label),\n",
    "                                  color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    true_label = true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zh9yABaME29S"
   },
   "source": [
    "### Verify predictions\n",
    "\n",
    "With the model trained, you can use it to make predictions about some images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4Ov9OFDMmOD"
   },
   "source": [
    "Let's look at a certain image, predictions, and prediction array. Correct prediction labels are blue and incorrect prediction labels are red. The number gives the percentage (out of 100) for the predicted label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HV5jw-5HwSmO"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgdvGD52CaXR"
   },
   "source": [
    "Let's plot several images with their predictions. Note that the model can be wrong even when very confident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQlnbqaw2Qu_"
   },
   "outputs": [],
   "source": [
    "# Plot the first X test images, their predicted labels, and the true labels.\n",
    "# Color correct predictions in blue and incorrect predictions in red.\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_image(i, predictions[i], test_labels, test_images)\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(i, predictions[i], test_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the trained model\n",
    "\n",
    "Call [`model.save`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#save) to save a model's architecture, weights, and training configuration in a single file/folder. This allows you to export a model so it can be used without access to the original Python code*.\n",
    "\n",
    "Saving a fully-functional model is very useful—you can load them in [TensorFlow JS](https://www.tensorflow.org/js/guide) and then train and run them in web browsers, or convert them to run on mobile devices using [TensorFlow Lite](https://www.tensorflow.org/lite/guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload a fresh Keras model from the saved model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also [save checkpoints during training](https://www.tensorflow.org/tutorials/keras/save_and_load#save_checkpoints_during_training), which allows us to pick-up training where we left off in case the training process was interrupted. The [`tf.keras.callbacks.ModelCheckpoint`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint) callback allows us to continually save the model both *during* and at *the end* of training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R32zteKHCaXT"
   },
   "source": [
    "## Use the loaded model\n",
    "\n",
    "Finally, use the loaded model to make a prediction about a single image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRJ7JU7JCaXT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vz3bVp21CaXV"
   },
   "source": [
    "`tf.keras` models are optimized to make predictions on a *batch*, or collection, of examples at once. Accordingly, even though you're using a single image, you need to add it to a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lDFh5yF_CaXW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQ5wLTkcCaXY"
   },
   "source": [
    "Now predict the correct label for this image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_rzNSdrCaXY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cU1Y2OAMCaXb"
   },
   "source": [
    "`tf.keras.Model.predict` returns a list of lists—one list for each image in the batch of data. Grab the predictions for our (only) image in the batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Ai-cpLjO-3A"
   },
   "outputs": [],
   "source": [
    "plot_value_array(1, predictions_single[0], test_labels)\n",
    "plt.xticks(range(10), list(range(10)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFc2HbEVCaXd"
   },
   "source": [
    "And the model predicts a label as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.argmax(predictions_single[0]) == test_labels[1]:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Know TensorBoard\n",
    "[TensorBoard](https://tensorflow.google.cn/tensorboard) is a tool for providing the measurements and visualizations needed during the machine learning workflow. It enables tracking experiment metrics like loss and accuracy, visualizing the model graph, projecting embeddings to a lower dimensional space, and much more.\n",
    "\n",
    "Recall that previously we have added a callback method into the training process. This logs all necessary information needed by TensorBoard and we could easily visualise what we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open an embedded TensorBoard viewer\n",
    "%tensorboard --logdir {logdir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WebApp\n",
    "\n",
    "We are going to build a web application based on [*TensorFlow.js*](https://www.tensorflow.org/js/guide) and use our trained model. It accepts real user drawing of digit and makes prediction on that.\n",
    "\n",
    "To Convert a saved model to a web format model usable by tf.js, do the following:\n",
    "\n",
    "```\n",
    "% pip install tensorflowjs\n",
    "% tensorflowjs_converter --input_format=tf_saved_model saved_model/ web_model/\n",
    "```\n",
    "\n",
    "<img src=\"./assets/webapp.png\" alt=\"webApp\">"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "colab_notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
