{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Height vs Weight\n",
    "\n",
    "Welcome to Core Workshop 4: Polynomial Regression's live code session\n",
    "\n",
    "Today we are dealing with a csv toy dataset taken from Kaggle: [https://www.kaggle.com/sakshamjn/heightvsweight-for-linear-polynomial-regression](https://www.kaggle.com/sakshamjn/heightvsweight-for-linear-polynomial-regression), which records the **weight** and **height** of people (they are made up). The data is already cleaned.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this session we are using this data to build a `polynomial regression` model, trying to predict the **height** by a given **weight**, using k-folds cross validation method to find optimal hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat previous processing\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"./data/HeightVsWeight.csv\")\n",
    "\n",
    "x = df.iloc[:, :1]\n",
    "y = df.iloc[:, 1:]\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.scatter(x, y, color=\"purple\")\n",
    "plt.xlabel(\"Weight\")\n",
    "plt.ylabel(\"Height\")\n",
    "plt.title(\"Height VS Weight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split using k-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to split the training data into 5 folds, which is common number used for small datasets\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "# Regular train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=1)\n",
    "\n",
    "# Build 5-folds split, split by index\n",
    "kf5 = KFold(n_splits=5)\n",
    "\n",
    "# Save the train index and validate index\n",
    "t_v_indexes = []\n",
    "\n",
    "for train_index, validation_index in kf5.split(x_train):\n",
    "    t_v_indexes.append([train_index, validation_index])\n",
    "    print(\"Train: {} | Validate: {}\".format(train_index, validation_index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training (Hyperparameter optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are iterating through each fold, for a range of hyperparameter, and take average accuracy to find the best hyperparameter\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# Let's range it to 10, because it doesn't seem to be a very tortuous dataset\n",
    "n = 20\n",
    "\n",
    "hyper_average = dict()\n",
    "\n",
    "# For each degree setting\n",
    "for i in range(1, n+1):\n",
    "\n",
    "    # Build respective pipeline and initialize sum\n",
    "    sum = 0\n",
    "    pipeline = make_pipeline(PolynomialFeatures(degree=i), LinearRegression())\n",
    "\n",
    "    # For each fold's train index and validation index\n",
    "    for train_index, validation_index in t_v_indexes:\n",
    "\n",
    "        cur_train_fold_x = x_train.iloc[train_index]\n",
    "        cur_train_fold_y = y_train.iloc[train_index]\n",
    "\n",
    "        cur_validation_fold_x = x_train.iloc[validation_index]\n",
    "        cur_validation_fold_y = y_train.iloc[validation_index]\n",
    "\n",
    "        pipeline.fit(cur_train_fold_x, cur_train_fold_y)\n",
    "        sum += pipeline.score(cur_validation_fold_x, cur_validation_fold_y)\n",
    "\n",
    "    # Add average to the performance\n",
    "    hyper_average[i] = sum/len(t_v_indexes)\n",
    "\n",
    "for key in hyper_average:\n",
    "    print(\"For degree {}, the average accuracy score is {}.\".format(key, round(hyper_average.get(key), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_degree = max(hyper_average, key=hyper_average.get)\n",
    "print(\"The best prediction degree is {}, with average accuracy of {}\".format(best_degree, hyper_average.get(best_degree)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to the pipeline, this whole process can be simplified using cross_val_score function from sklearn, it uses k-folds method cross validation by default\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "n = 20\n",
    "\n",
    "hyper_average = [None] * n\n",
    "\n",
    "for i in range(n):\n",
    "    pipeline = make_pipeline(PolynomialFeatures(degree=i+1), LinearRegression())\n",
    "    hyper_average[i] = np.mean(cross_val_score(pipeline, x_train, y_train, cv=5))\n",
    "\n",
    "# Plus one because list are 0-indexed, unlike how we defined our dictionary\n",
    "best_degree = hyper_average.index(max(hyper_average))\n",
    "print(\"The best prediction degree is {}, with average accuracy of {}\".format(best_degree+1, hyper_average[best_degree]))\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(np.arange(1, 21), hyper_average, color=\"purple\")\n",
    "plt.xlabel(\"Model Complexity (degree)\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.title(\"Accuracy score from different degrees\")\n",
    "plt.xlim(1, 20)\n",
    "plt.ylim(0.990, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: our best degree is 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training (Parameter optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "model = make_pipeline(PolynomialFeatures(degree=best_degree+1), LinearRegression())\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Model training completed\")\n",
    "rand = np.array([[random.randint(10, 80)]])\n",
    "print(\"Trying to predict a person with a weight of {} kg will have a height of {} cm\".format(rand[0][0], round(model.predict(rand)[0][0], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does it look like?\n",
    "\n",
    "x_test = x_test.sort_values(\"Weight\")\n",
    "y_test = y_test.reindex(x_test.index)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.scatter(x, y, color=\"purple\")\n",
    "plt.plot(x_test, model.predict(x_test), color=\"black\", linewidth=5)\n",
    "plt.xlabel(\"Weight\")\n",
    "plt.ylabel(\"Height\")\n",
    "plt.title(\"Height VS Weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score = model.score(x_test, y_test)\n",
    "print(\"Model Accuracy: {}\".format(round(accuracy_score, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is almost 100% correct everytime, the best we can do avoiding overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
